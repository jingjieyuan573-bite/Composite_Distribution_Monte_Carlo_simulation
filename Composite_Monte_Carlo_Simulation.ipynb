{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+hoQ0OAqA9TN86xUycg8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jingjieyuan573-bite/Composite_Distribution_analysis/blob/main/Composite_Monte_Carlo_Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# Composite Monte Carlo Simulation (Fixed, Corrected, and Sensitivity-Enhanced)\n",
        "\n",
        "# This script runs Monte Carlo comparisons between three models:\n",
        "# - Composite (center: skew-normal; tails: skew-t)\n",
        "# - Skew-t\n",
        "# - Skew-normal\n",
        "\n",
        "# Features:\n",
        "# - monte_carlo_sim(M,n): one Monte Carlo experiment\n",
        "# - bootstrap_ci: bootstrap 95% CI for grouped means\n",
        "# - run_sample_size_sensitivity: run experiments for multiple n and produce CSV + LaTeX output\n",
        "\n",
        "# This version fixes all syntax issues and unterminated string literals and adds full sample-size sensitivity analysis with bootstrap CIs, directly displaying results.\n",
        "# \"\"\"\n",
        "\n",
        "# import time\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from scipy import stats\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # ---------- RNG helper ----------\n",
        "\n",
        "# def ensure_rng(rs=None):\n",
        "#     if rs is None:\n",
        "#         return np.random.RandomState(None)\n",
        "#     if isinstance(rs, (int, np.integer)):\n",
        "#         return np.random.RandomState(int(rs))\n",
        "#     if isinstance(rs, np.random.RandomState):\n",
        "#         return rs\n",
        "#     return np.random.RandomState(None)\n",
        "\n",
        "# # ---------- Skew-t sampling ----------\n",
        "\n",
        "# def skewt_rvs(xi=0.0, omega=1.0, alpha=0.0, nu=8.0, size=1, random_state=None):\n",
        "#     rng = ensure_rng(random_state)\n",
        "#     U = stats.skewnorm.rvs(alpha, loc=0.0, scale=1.0, size=size, random_state=rng)\n",
        "#     S = rng.chisquare(nu, size=size)\n",
        "#     return xi + omega * U * np.sqrt(nu / S)\n",
        "\n",
        "# # ---------- Composite sampling ----------\n",
        "\n",
        "# def composite_rvs(size=1, xi=0.0, omega=1.0, alpha=15.0, nu=6.0,\n",
        "#                   theta1=-2.0, theta2=2, left_frac=0.08, right_frac=0.08, random_state=None):\n",
        "#     rng = ensure_rng(random_state)\n",
        "#     n = int(size)\n",
        "#     samples = np.empty(n, dtype=float)\n",
        "#     u = rng.rand(n)\n",
        "#     r1 = left_frac; r2 = right_frac\n",
        "#     comp = np.where(u < r1, 0, np.where(u < r1 + (1 - r1 - r2), 1, 2))\n",
        "\n",
        "#     for k in (0, 1, 2):\n",
        "#         idx = np.where(comp == k)[0]\n",
        "#         if idx.size == 0:\n",
        "#             continue\n",
        "#         need = idx.size\n",
        "#         draws = []\n",
        "#         while len(draws) < need:\n",
        "#             if k == 1:\n",
        "#                 batch = stats.skewnorm.rvs(alpha, loc=xi, scale=omega, size=max(need * 2, 500), random_state=rng)\n",
        "#                 valid = batch[(batch > theta1) & (batch < theta2)]\n",
        "#             else:\n",
        "#                 batch = skewt_rvs(xi=xi, omega=omega, alpha=alpha, nu=nu, size=max(need * 2, 500), random_state=rng)\n",
        "#                 if k == 0:\n",
        "#                     valid = batch[batch <= theta1]\n",
        "#                 else:\n",
        "#                     valid = batch[batch >= theta2]\n",
        "#             draws.extend(valid.tolist())\n",
        "#         samples[idx] = np.array(draws[:need])\n",
        "#     return samples\n",
        "\n",
        "# # ---------- Empirical CDF factory ----------\n",
        "\n",
        "# def empirical_cdf_factory(sample):\n",
        "#     s = np.sort(np.asarray(sample))\n",
        "#     n = len(s)\n",
        "#     def cdf(x):\n",
        "#         x = np.asarray(x)\n",
        "#         return np.searchsorted(s, x, side='right') / float(n)\n",
        "#     return cdf\n",
        "\n",
        "# # ---------- Tail KS ----------\n",
        "\n",
        "# def compute_tailks(cdf_func, data_sorted, upper_pct, lower_pct):\n",
        "#     lower_val = np.percentile(data_sorted, lower_pct)\n",
        "#     upper_val = np.percentile(data_sorted, upper_pct)\n",
        "#     tail_points = np.concatenate([data_sorted[data_sorted <= lower_val], data_sorted[data_sorted >= upper_val]])\n",
        "#     if len(tail_points) == 0:\n",
        "#         return np.nan\n",
        "#     fitted_vals = np.asarray(cdf_func(tail_points))\n",
        "#     n = len(data_sorted)\n",
        "#     empirical_vals = np.searchsorted(data_sorted, tail_points, side='right') / float(n)\n",
        "#     return float(np.max(np.abs(fitted_vals - empirical_vals)))\n",
        "\n",
        "# # ---------- Log-likelihood ----------\n",
        "\n",
        "# def loglikelihood(model_name, x):\n",
        "#     x = np.asarray(x)\n",
        "#     if model_name == 'Composite':\n",
        "#         ll = np.zeros_like(x, dtype=float)\n",
        "#         left_mask = x <= -1\n",
        "#         mid_mask = (x > -1) & (x < 0.2)\n",
        "#         right_mask = x >= 0.2\n",
        "#         if np.any(left_mask):\n",
        "#             ll[left_mask] = stats.t.pdf(x[left_mask], df=6, loc=0, scale=1)\n",
        "#         if np.any(mid_mask):\n",
        "#             ll[mid_mask] = stats.skewnorm.pdf(x[mid_mask], a=15, loc=0, scale=1)\n",
        "#         if np.any(right_mask):\n",
        "#             ll[right_mask] = stats.t.pdf(x[right_mask], df=6, loc=0, scale=1)\n",
        "#         return np.log(np.maximum(ll, 1e-12))\n",
        "#     elif model_name == 'Skew-t':\n",
        "#         return np.log(stats.t.pdf(x, df=5, loc=0, scale=1))\n",
        "#     else:\n",
        "#         return np.log(stats.skewnorm.pdf(x, a=6, loc=0, scale=1))\n",
        "\n",
        "# # ---------- Monte Carlo simulation ----------\n",
        "\n",
        "# def monte_carlo_sim(M=50, n=2000, seed=1234, rng=None, mc_sample_size=20000):\n",
        "#     \"\"\"\n",
        "#     Run Monte Carlo: generate data from composite DGP and evaluate three candidate models.\n",
        "#     For each replication we :\n",
        "#       - draw one dataset from the composite DGP;\n",
        "#       - fit simple parametric approximations to each candidate model using the dataset (so fitted CDFs reflect estimation error);\n",
        "#       - draw a large parametric sample from each fitted model (mc_sample_size) to form the fitted CDF;\n",
        "#       - compute TailKS between the observed data and each fitted model; compute bias/MSE from model-implied draws;\n",
        "#       - compute average log-likelihood of the observed data under the fitted model.\n",
        "\n",
        "#     This approach avoids TailKS==0 (which happens when comparing the dataset to its own empirical CDF)\n",
        "#     and gives a realistic, non-degenerate comparison.\n",
        "#     \"\"\"\n",
        "#     rng = ensure_rng(rng if rng is not None else seed)\n",
        "#     rows = []\n",
        "\n",
        "#     for rep in range(int(M)):\n",
        "#         # draw one dataset from the composite DGP\n",
        "#         data = composite_rvs(size=n, xi=0.0, omega=1.0, alpha=15.0, nu=6.0,\n",
        "#                              theta1=-2, theta2=2, left_frac=0.08, right_frac=0.08, random_state=rng)\n",
        "#         data_sorted = np.sort(data)\n",
        "\n",
        "#         # split observed data for composite-fitting convenience\n",
        "#         theta1, theta2 = -2, 2\n",
        "#         left_obs = data[data <= theta1]\n",
        "#         mid_obs = data[(data > theta1) & (data < theta2)]\n",
        "#         right_obs = data[data >= theta2]\n",
        "#         n_left, n_mid, n_right = len(left_obs), len(mid_obs), len(right_obs)\n",
        "\n",
        "#         for model_name in ['Composite', 'Skew-t', 'Skew-normal']:\n",
        "#             # Fit model parameters from the observed data (simple, robust fits)\n",
        "#             try:\n",
        "#                 if model_name == 'Composite':\n",
        "#                     # estimate region weights\n",
        "#                     r1_est = max(1e-6, n_left / float(n))\n",
        "#                     r2_est = max(1e-6, n_right / float(n))\n",
        "#                     rmid_est = max(1e-6, 1.0 - r1_est - r2_est)\n",
        "\n",
        "#                     # fit center skew-normal if enough data, else fallback to canonical\n",
        "#                     if n_mid >= 10:\n",
        "#                         try:\n",
        "#                             a_c, loc_c, scale_c = stats.skewnorm.fit(mid_obs)\n",
        "#                         except Exception:\n",
        "#                             a_c, loc_c, scale_c = 15.0, 0.0, 1.0\n",
        "#                     else:\n",
        "#                         a_c, loc_c, scale_c = 15.0, 0.0, 1.0\n",
        "\n",
        "#                     # fit tails (t) if enough data\n",
        "#                     if n_left >= 10:\n",
        "#                         try:\n",
        "#                             df_l, loc_l, scale_l = stats.t.fit(left_obs)\n",
        "#                         except Exception:\n",
        "#                             df_l, loc_l, scale_l = 6.0, 0.0, 1.0\n",
        "#                     else:\n",
        "#                         df_l, loc_l, scale_l = 6.0, 0.0, 1.0\n",
        "\n",
        "#                     if n_right >= 10:\n",
        "#                         try:\n",
        "#                             df_r, loc_r, scale_r = stats.t.fit(right_obs)\n",
        "#                         except Exception:\n",
        "#                             df_r, loc_r, scale_r = 6.0, 0.0, 1.0\n",
        "#                     else:\n",
        "#                         df_r, loc_r, scale_r = 6.0, 0.0, 1.0\n",
        "\n",
        "#                     # build a parametric sample from the fitted composite model\n",
        "#                     n_left_s = max(1, int(mc_sample_size * r1_est))\n",
        "#                     n_mid_s = max(1, int(mc_sample_size * rmid_est))\n",
        "#                     n_right_s = max(1, mc_sample_size - n_left_s - n_mid_s)\n",
        "\n",
        "#                     left_sample = stats.t.rvs(df_l, loc=loc_l, scale=scale_l, size=n_left_s, random_state=rng)\n",
        "#                     mid_sample = stats.skewnorm.rvs(a_c, loc=loc_c, scale=scale_c, size=n_mid_s, random_state=rng)\n",
        "#                     right_sample = stats.t.rvs(df_r, loc=loc_r, scale=scale_r, size=n_right_s, random_state=rng)\n",
        "\n",
        "#                     param_sample = np.concatenate([left_sample, mid_sample, right_sample])\n",
        "\n",
        "#                     # compute per-observation log-likelihood under the fitted composite\n",
        "#                     ll_vals = np.empty_like(data)\n",
        "#                     left_mask = data <= theta1\n",
        "#                     mid_mask = (data > theta1) & (data < theta2)\n",
        "#                     right_mask = data >= theta2\n",
        "#                     if np.any(left_mask):\n",
        "#                         ll_vals[left_mask] = stats.t.pdf(data[left_mask], df=df_l, loc=loc_l, scale=scale_l)\n",
        "#                     if np.any(mid_mask):\n",
        "#                         ll_vals[mid_mask] = stats.skewnorm.pdf(data[mid_mask], a=a_c, loc=loc_c, scale=scale_c)\n",
        "#                     if np.any(right_mask):\n",
        "#                         ll_vals[right_mask] = stats.t.pdf(data[right_mask], df=df_r, loc=loc_r, scale=scale_r)\n",
        "#                     avg_loglike = float(np.mean(np.log(np.maximum(ll_vals, 1e-12))))\n",
        "\n",
        "#                 elif model_name == 'Skew-t':\n",
        "#                     # approximate skew-t by fitting a Student-t (no skew param in scipy)\n",
        "#                     try:\n",
        "#                         df_t, loc_t, scale_t = stats.t.fit(data)\n",
        "#                     except Exception:\n",
        "#                         df_t, loc_t, scale_t = 6.0, 0.0, 1.0\n",
        "#                     param_sample = stats.t.rvs(df_t, loc=loc_t, scale=scale_t, size=mc_sample_size, random_state=rng)\n",
        "#                     avg_loglike = float(np.mean(stats.t.logpdf(data, df=df_t, loc=loc_t, scale=scale_t)))\n",
        "\n",
        "#                 else:  # Skew-normal\n",
        "#                     try:\n",
        "#                         a_sn, loc_sn, scale_sn = stats.skewnorm.fit(data)\n",
        "#                     except Exception:\n",
        "#                         a_sn, loc_sn, scale_sn = 6.0, 0.0, 1.0\n",
        "#                     param_sample = stats.skewnorm.rvs(a_sn, loc=loc_sn, scale=scale_sn, size=mc_sample_size, random_state=rng)\n",
        "#                     avg_loglike = float(np.mean(stats.skewnorm.logpdf(data, a_sn, loc=loc_sn, scale=scale_sn)))\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 # fallback: use canonical parameters if any fit fails\n",
        "#                 if model_name == 'Composite':\n",
        "#                     param_sample = composite_rvs(size=mc_sample_size, random_state=rng)\n",
        "#                     avg_loglike = float(np.mean(loglikelihood('Composite', data)))\n",
        "#                 elif model_name == 'Skew-t':\n",
        "#                     param_sample = skewt_rvs(size=mc_sample_size, random_state=rng)\n",
        "#                     avg_loglike = float(np.mean(loglikelihood('Skew-t', data)))\n",
        "#                 else:\n",
        "#                     param_sample = stats.skewnorm.rvs(a=6.0, loc=0.0, scale=1.0, size=mc_sample_size, random_state=rng)\n",
        "#                     avg_loglike = float(np.mean(loglikelihood('Skew-normal', data)))\n",
        "\n",
        "#             # make fitted cdf from the parametric sample (reflects estimated parameters)\n",
        "#             fitted_cdf = empirical_cdf_factory(param_sample)\n",
        "\n",
        "#             # TailKS comparing observed data vs fitted model CDF\n",
        "#             tailks = compute_tailks(fitted_cdf, data_sorted, 95, 5)\n",
        "\n",
        "#             # compute model-implied moments (draw a size-n sample from param_sample)\n",
        "#             sim_draw = rng.choice(param_sample, size=n, replace=False) if len(param_sample) >= n else rng.choice(param_sample, size=n, replace=True)\n",
        "#             bias_mean = float(np.mean(sim_draw))\n",
        "#             mse_mean = float(np.mean((sim_draw - 0.0) ** 2))\n",
        "\n",
        "#             rows.append({'rep': int(rep), 'model': model_name, 'avg_loglike': avg_loglike,\n",
        "#                          'tailks': tailks, 'bias_mean': bias_mean, 'mse_mean': mse_mean})\n",
        "\n",
        "#     return pd.DataFrame(rows)\n",
        "\n",
        "# # ---------- Bootstrap CI ----------\n",
        "\n",
        "# def bootstrap_ci(df, model, col, B=500, alpha=0.05, rng=None):\n",
        "#     rng = ensure_rng(rng)\n",
        "#     vals = df[df['model'] == model][col].values\n",
        "#     n = len(vals)\n",
        "#     if n == 0:\n",
        "#         return (np.nan, np.nan)\n",
        "#     boot_means = [np.mean(rng.choice(vals, size=n, replace=True)) for _ in range(int(B))]\n",
        "#     lo = np.percentile(boot_means, 100 * alpha / 2)\n",
        "#     hi = np.percentile(boot_means, 100 * (1 - alpha / 2))\n",
        "#     return float(lo), float(hi)\n",
        "\n",
        "# # ---------- Run sample-size sensitivity with bootstrap ----------\n",
        "\n",
        "# def run_sample_size_sensitivity(sample_sizes=[2000], M=500, B_boot=500, seed=1234, quick=False):\n",
        "#     rng = ensure_rng(seed)\n",
        "#     M_use, B_use = (max(10, int(M // 10)), max(50, int(B_boot // 10))) if quick else (int(M), int(B_boot))\n",
        "\n",
        "#     results = []\n",
        "\n",
        "#     for n in sample_sizes:\n",
        "#         t0 = time.time()\n",
        "#         print(f\"\\nRunning Monte Carlo simulation with sample size {n}\")\n",
        "#         df = monte_carlo_sim(M=M_use, n=n, seed=seed, rng=rng)\n",
        "\n",
        "#         summary = df.groupby('model')[['avg_loglike','tailks','bias_mean','mse_mean']].mean().reset_index()\n",
        "#         print(\"\\nMonte Carlo results (averaged over repetitions):\")\n",
        "#         print(summary)\n",
        "\n",
        "#         # Compute bootstrap CIs\n",
        "#         for model in summary['model']:\n",
        "#             ci_avgloglike = bootstrap_ci(df, model, 'avg_loglike', B=B_use, rng=rng)\n",
        "#             ci_tailks = bootstrap_ci(df, model, 'tailks', B=B_use, rng=rng)\n",
        "#             ci_bias = bootstrap_ci(df, model, 'bias_mean', B=B_use, rng=rng)\n",
        "#             ci_mse = bootstrap_ci(df, model, 'mse_mean', B=B_use, rng=rng)\n",
        "#             print(f\"\\n{model} 95% CI:\")\n",
        "#             print(f\"  Avg LOGLIKE: {ci_avgloglike}\")\n",
        "#             print(f\"  Tail KS   : {ci_tailks}\")\n",
        "#             print(f\"  Bias      : {ci_bias}\")\n",
        "#             print(f\"  MSE       : {ci_mse}\")\n",
        "\n",
        "#     return df, summary\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # 小规模测试，快速看到输出\n",
        "#     df, summary = run_sample_size_sensitivity(\n",
        "#         sample_sizes=[2000],  # 这里可以改回 [500,2000,5000]\n",
        "#         M=50,                      # 可以改回 500\n",
        "#         B_boot=100,                # 可以改回 500\n",
        "#         seed=1234,\n",
        "#         quick=True                 # quick=True 只做少量重复，快速看到结果\n",
        "#     )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "xky8qfX-cFfI",
        "outputId": "8592c237-efce-4af0-ff5a-674e0158d2ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Monte Carlo simulation with sample size 2000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3165953476.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;31m# 小规模测试，快速看到输出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     df, summary = run_sample_size_sensitivity(\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0msample_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 这里可以改回 [500,2000,5000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0;31m# 可以改回 500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3165953476.py\u001b[0m in \u001b[0;36mrun_sample_size_sensitivity\u001b[0;34m(sample_sizes, M, B_boot, seed, quick)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nRunning Monte Carlo simulation with sample size {n}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonte_carlo_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_loglike'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tailks'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bias_mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mse_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3165953476.py\u001b[0m in \u001b[0;36mmonte_carlo_sim\u001b[0;34m(M, n, seed, rng, mc_sample_size)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# draw one dataset from the composite DGP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         data = composite_rvs(size=n, xi=0.0, omega=1.0, alpha=15.0, nu=6.0,\n\u001b[0m\u001b[1;32m    139\u001b[0m                              theta1=-2, theta2=2, left_frac=0.08, right_frac=0.08, random_state=rng)\n\u001b[1;32m    140\u001b[0m         \u001b[0mdata_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3165953476.py\u001b[0m in \u001b[0;36mcomposite_rvs\u001b[0;34m(size, xi, omega, alpha, nu, theta1, theta2, left_frac, right_frac, random_state)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtheta1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtheta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskewt_rvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneed\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtheta1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3165953476.py\u001b[0m in \u001b[0;36mskewt_rvs\u001b[0;34m(xi, omega, alpha, nu, size, random_state)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mskewt_rvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskewnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchisquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0momega\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0mdiscrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'discrete'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0mrndm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'random_state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args_rvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m_parse_args_rvs\u001b[0;34m(self, a, loc, scale, size)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_argcheck_rvs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;31m# The only keyword argument expected is 'size'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mall_bcast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msqueeze_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_stride_tricks_impl.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(subok, *args)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;31m#                  order='C').itviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Composite Monte Carlo Simulation (Fixed / Self-contained)\n",
        "\n",
        "- Fixed RNG handling and result aggregation across sample sizes.\n",
        "- Saves summary CSV and LaTeX.\n",
        "- Default run: n=2000, M=50 (quick small run). Adjust M, B_boot for larger experiments.\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ---------- RNG helper ----------\n",
        "def ensure_rng(rs=None):\n",
        "    if rs is None:\n",
        "        return np.random.RandomState(None)\n",
        "    if isinstance(rs, (int, np.integer)):\n",
        "        return np.random.RandomState(int(rs))\n",
        "    if isinstance(rs, np.random.RandomState):\n",
        "        return rs\n",
        "    return np.random.RandomState(None)\n",
        "\n",
        "# ---------- Skew-t sampling ----------\n",
        "def skewt_rvs(xi=0.0, omega=1.0, alpha=0.0, nu=8.0, size=1, random_state=None):\n",
        "    rng = ensure_rng(random_state)\n",
        "    U = stats.skewnorm.rvs(alpha, loc=0.0, scale=1.0, size=size, random_state=rng)\n",
        "    S = rng.chisquare(nu, size=size)\n",
        "    return xi + omega * U * np.sqrt(nu / S)\n",
        "\n",
        "# ---------- Composite sampling ----------\n",
        "def composite_rvs(size=1, xi=0.0, omega=1.0, alpha=15.0, nu=6.0,\n",
        "                  theta1=-0.3, theta2=0.3, left_frac=0.08, right_frac=0.08, random_state=None):\n",
        "    rng = ensure_rng(random_state)\n",
        "    n = int(size)\n",
        "    samples = np.empty(n, dtype=float)\n",
        "    u = rng.rand(n)\n",
        "    r1 = left_frac; r2 = right_frac\n",
        "    comp = np.where(u < r1, 0, np.where(u < r1 + (1 - r1 - r2), 1, 2))\n",
        "\n",
        "    for k in (0, 1, 2):\n",
        "        idx = np.where(comp == k)[0]\n",
        "        if idx.size == 0:\n",
        "            continue\n",
        "        need = idx.size\n",
        "        draws = []\n",
        "        # rejection sampling batches; avoid pathological infinite loop by large batch size\n",
        "        while len(draws) < need:\n",
        "            if k == 1:\n",
        "                batch = stats.skewnorm.rvs(alpha, loc=xi, scale=omega, size=max(need * 2, 500), random_state=rng)\n",
        "                valid = batch[(batch > theta1) & (batch < theta2)]\n",
        "            else:\n",
        "                batch = skewt_rvs(xi=xi, omega=omega, alpha=alpha, nu=nu, size=max(need * 2, 500), random_state=rng)\n",
        "                if k == 0:\n",
        "                    valid = batch[batch <= theta1]\n",
        "                else:\n",
        "                    valid = batch[batch >= theta2]\n",
        "            draws.extend(valid.tolist())\n",
        "        samples[idx] = np.array(draws[:need])\n",
        "    return samples\n",
        "\n",
        "# ---------- Empirical CDF factory ----------\n",
        "def empirical_cdf_factory(sample):\n",
        "    s = np.sort(np.asarray(sample))\n",
        "    n = len(s)\n",
        "    def cdf(x):\n",
        "        x = np.asarray(x)\n",
        "        return np.searchsorted(s, x, side='right') / float(n)\n",
        "    return cdf\n",
        "\n",
        "# ---------- Tail KS ----------\n",
        "def compute_tailks(cdf_func, data_sorted, upper_pct, lower_pct):\n",
        "    lower_val = np.percentile(data_sorted, lower_pct)\n",
        "    upper_val = np.percentile(data_sorted, upper_pct)\n",
        "    tail_points = np.concatenate([data_sorted[data_sorted <= lower_val], data_sorted[data_sorted >= upper_val]])\n",
        "    if len(tail_points) == 0:\n",
        "        return np.nan\n",
        "    fitted_vals = np.asarray(cdf_func(tail_points))\n",
        "    n = len(data_sorted)\n",
        "    empirical_vals = np.searchsorted(data_sorted, tail_points, side='right') / float(n)\n",
        "    return float(np.max(np.abs(fitted_vals - empirical_vals)))\n",
        "\n",
        "# ---------- Log-likelihood (fallback only) ----------\n",
        "def loglikelihood(model_name, x):\n",
        "    x = np.asarray(x)\n",
        "    if model_name == 'Composite':\n",
        "        ll = np.zeros_like(x, dtype=float)\n",
        "        left_mask = x <= -1\n",
        "        mid_mask = (x > -1) & (x < 0.2)\n",
        "        right_mask = x >= 0.2\n",
        "        if np.any(left_mask):\n",
        "            ll[left_mask] = stats.t.pdf(x[left_mask], df=6, loc=0, scale=1)\n",
        "        if np.any(mid_mask):\n",
        "            ll[mid_mask] = stats.skewnorm.pdf(x[mid_mask], a=15, loc=0, scale=1)\n",
        "        if np.any(right_mask):\n",
        "            ll[right_mask] = stats.t.pdf(x[right_mask], df=6, loc=0, scale=1)\n",
        "        return np.log(np.maximum(ll, 1e-12))\n",
        "    elif model_name == 'Skew-t':\n",
        "        return np.log(stats.t.pdf(x, df=5, loc=0, scale=1))\n",
        "    else:\n",
        "        return np.log(stats.skewnorm.pdf(x, a=6, loc=0, scale=1))\n",
        "\n",
        "# ---------- Monte Carlo simulation ----------\n",
        "def monte_carlo_sim(M=500, n=5000, seed=1, rng=None, mc_sample_size=20000):\n",
        "    rng = ensure_rng(rng if rng is not None else seed)\n",
        "    rows = []\n",
        "\n",
        "    for rep in range(int(M)):\n",
        "        # draw one dataset from the composite DGP\n",
        "        data = composite_rvs(size=n, xi=0.0, omega=1.0, alpha=15.0, nu=6.0,\n",
        "                             theta1=-0.3, theta2=0.3, left_frac=0.08, right_frac=0.08, random_state=rng)\n",
        "        data_sorted = np.sort(data)\n",
        "\n",
        "        # split observed data for composite-fitting convenience\n",
        "        theta1, theta2 = -0.3, 0.3\n",
        "        left_obs = data[data <= theta1]\n",
        "        mid_obs = data[(data > theta1) & (data < theta2)]\n",
        "        right_obs = data[data >= theta2]\n",
        "        n_left, n_mid, n_right = len(left_obs), len(mid_obs), len(right_obs)\n",
        "\n",
        "        for model_name in ['Composite', 'Skew-t', 'Skew-normal']:\n",
        "            try:\n",
        "                if model_name == 'Composite':\n",
        "                    # estimate region weights\n",
        "                    r1_est = max(1e-6, n_left / float(n))\n",
        "                    r2_est = max(1e-6, n_right / float(n))\n",
        "                    rmid_est = max(1e-6, 1.0 - r1_est - r2_est)\n",
        "\n",
        "                    # fit center skew-normal if enough data, else fallback to canonical\n",
        "                    if n_mid >= 10:\n",
        "                        try:\n",
        "                            a_c, loc_c, scale_c = stats.skewnorm.fit(mid_obs)\n",
        "                        except Exception:\n",
        "                            a_c, loc_c, scale_c = 15.0, 0.0, 1.0\n",
        "                    else:\n",
        "                        a_c, loc_c, scale_c = 15.0, 0.0, 1.0\n",
        "\n",
        "                    # fit tails (t) if enough data\n",
        "                    if n_left >= 10:\n",
        "                        try:\n",
        "                            df_l, loc_l, scale_l = stats.t.fit(left_obs)\n",
        "                        except Exception:\n",
        "                            df_l, loc_l, scale_l = 6.0, 0.0, 1.0\n",
        "                    else:\n",
        "                        df_l, loc_l, scale_l = 6.0, 0.0, 1.0\n",
        "\n",
        "                    if n_right >= 10:\n",
        "                        try:\n",
        "                            df_r, loc_r, scale_r = stats.t.fit(right_obs)\n",
        "                        except Exception:\n",
        "                            df_r, loc_r, scale_r = 6.0, 0.0, 1.0\n",
        "                    else:\n",
        "                        df_r, loc_r, scale_r = 6.0, 0.0, 1.0\n",
        "\n",
        "                    # build a parametric sample from the fitted composite model\n",
        "                    n_left_s = max(1, int(mc_sample_size * r1_est))\n",
        "                    n_mid_s = max(1, int(mc_sample_size * rmid_est))\n",
        "                    n_right_s = max(1, mc_sample_size - n_left_s - n_mid_s)\n",
        "\n",
        "                    left_sample = stats.t.rvs(df_l, loc=loc_l, scale=scale_l, size=n_left_s, random_state=rng)\n",
        "                    mid_sample = stats.skewnorm.rvs(a_c, loc=loc_c, scale=scale_c, size=n_mid_s, random_state=rng)\n",
        "                    right_sample = stats.t.rvs(df_r, loc=loc_r, scale=scale_r, size=n_right_s, random_state=rng)\n",
        "\n",
        "                    param_sample = np.concatenate([left_sample, mid_sample, right_sample])\n",
        "\n",
        "                    # compute per-observation log-likelihood under the fitted composite\n",
        "                    ll_vals = np.empty_like(data)\n",
        "                    left_mask = data <= theta1\n",
        "                    mid_mask = (data > theta1) & (data < theta2)\n",
        "                    right_mask = data >= theta2\n",
        "                    if np.any(left_mask):\n",
        "                        ll_vals[left_mask] = stats.t.pdf(data[left_mask], df=df_l, loc=loc_l, scale=scale_l)\n",
        "                    if np.any(mid_mask):\n",
        "                        ll_vals[mid_mask] = stats.skewnorm.pdf(data[mid_mask], a=a_c, loc=loc_c, scale=scale_c)\n",
        "                    if np.any(right_mask):\n",
        "                        ll_vals[right_mask] = stats.t.pdf(data[right_mask], df=df_r, loc=loc_r, scale=scale_r)\n",
        "                    avg_loglike = float(np.mean(np.log(np.maximum(ll_vals, 1e-12))))\n",
        "\n",
        "                elif model_name == 'Skew-t':\n",
        "                    # approximate skew-t by fitting a Student-t (no skew param in scipy)\n",
        "                    try:\n",
        "                        df_t, loc_t, scale_t = stats.t.fit(data)\n",
        "                    except Exception:\n",
        "                        df_t, loc_t, scale_t = 6.0, 0.0, 1.0\n",
        "                    param_sample = stats.t.rvs(df_t, loc=loc_t, scale=scale_t, size=mc_sample_size, random_state=rng)\n",
        "                    avg_loglike = float(np.mean(stats.t.logpdf(data, df=df_t, loc=loc_t, scale=scale_t)))\n",
        "\n",
        "                else:  # Skew-normal\n",
        "                    try:\n",
        "                        a_sn, loc_sn, scale_sn = stats.skewnorm.fit(data)\n",
        "                    except Exception:\n",
        "                        a_sn, loc_sn, scale_sn = 6.0, 0.0, 1.0\n",
        "                    param_sample = stats.skewnorm.rvs(a_sn, loc=loc_sn, scale=scale_sn, size=mc_sample_size, random_state=rng)\n",
        "                    avg_loglike = float(np.mean(stats.skewnorm.logpdf(data, a_sn, loc=loc_sn, scale=scale_sn)))\n",
        "\n",
        "            except Exception as e:\n",
        "                # fallback: use canonical parameters if any fit fails\n",
        "                if model_name == 'Composite':\n",
        "                    param_sample = composite_rvs(size=mc_sample_size, random_state=rng)\n",
        "                    avg_loglike = float(np.mean(loglikelihood('Composite', data)))\n",
        "                elif model_name == 'Skew-t':\n",
        "                    param_sample = skewt_rvs(size=mc_sample_size, random_state=rng)\n",
        "                    avg_loglike = float(np.mean(loglikelihood('Skew-t', data)))\n",
        "                else:\n",
        "                    param_sample = stats.skewnorm.rvs(a=6.0, loc=0.0, scale=1.0, size=mc_sample_size, random_state=rng)\n",
        "                    avg_loglike = float(np.mean(loglikelihood('Skew-normal', data)))\n",
        "\n",
        "            # make fitted cdf from the parametric sample (reflects estimated parameters)\n",
        "            fitted_cdf = empirical_cdf_factory(param_sample)\n",
        "\n",
        "            # TailKS comparing observed data vs fitted model CDF\n",
        "            tailks = compute_tailks(fitted_cdf, data_sorted, 95, 5)\n",
        "\n",
        "            # compute model-implied moments (draw a size-n sample from param_sample)\n",
        "            sim_draw = rng.choice(param_sample, size=n, replace=False) if len(param_sample) >= n else rng.choice(param_sample, size=n, replace=True)\n",
        "            bias_mean = float(np.mean(sim_draw))\n",
        "            mse_mean = float(np.mean((sim_draw - 0.0) ** 2))\n",
        "\n",
        "            rows.append({'rep': int(rep), 'model': model_name, 'avg_loglike': avg_loglike,\n",
        "                         'tailks': tailks, 'bias_mean': bias_mean, 'mse_mean': mse_mean})\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Bootstrap CI ----------\n",
        "def bootstrap_ci(df, model, col, B=500, alpha=0.05, rng=None):\n",
        "    rng = ensure_rng(rng)\n",
        "    vals = df[df['model'] == model][col].values\n",
        "    n = len(vals)\n",
        "    if n == 0:\n",
        "        return (np.nan, np.nan)\n",
        "    boot_means = [np.mean(rng.choice(vals, size=n, replace=True)) for _ in range(int(B))]\n",
        "    lo = np.percentile(boot_means, 100 * alpha / 2)\n",
        "    hi = np.percentile(boot_means, 100 * (1 - alpha / 2))\n",
        "    return float(lo), float(hi)\n",
        "\n",
        "# ---------- Run sample-size sensitivity with bootstrap ----------\n",
        "def run_sample_size_sensitivity(sample_sizes=[5000], M=500, B_boot=500, seed=1234, quick=False, mc_sample_size=20000, out_prefix=\"mc_results\"):\n",
        "    rng_master = ensure_rng(seed)\n",
        "    if quick:\n",
        "        M_use = max(10, int(M // 10))\n",
        "        B_use = max(50, int(B_boot // 10))\n",
        "    else:\n",
        "        M_use, B_use = int(M), int(B_boot)\n",
        "\n",
        "    all_rows = []\n",
        "    summaries = []\n",
        "\n",
        "    for n in sample_sizes:\n",
        "        t0 = time.time()\n",
        "        print(f\"\\nRunning Monte Carlo simulation with sample size {n} (M={M_use}, B_boot={B_use})\")\n",
        "        # derive per-n RNG for reproducibility\n",
        "        rng_n = ensure_rng(rng_master.randint(2**31 - 1))\n",
        "\n",
        "        df_n = monte_carlo_sim(M=M_use, n=n, seed=None, rng=rng_n, mc_sample_size=mc_sample_size)\n",
        "        df_n['n'] = int(n)\n",
        "        all_rows.append(df_n)\n",
        "\n",
        "        # compute mean summary per model\n",
        "        summary = df_n.groupby('model')[['avg_loglike','tailks','bias_mean','mse_mean']].mean().reset_index()\n",
        "\n",
        "        for model in summary['model']:\n",
        "            ci_rng = ensure_rng(rng_n.randint(2**31 - 1))\n",
        "            ci_avgloglike = bootstrap_ci(df_n, model, 'avg_loglike', B=B_use, rng=ci_rng)\n",
        "            ci_tailks     = bootstrap_ci(df_n, model, 'tailks', B=B_use, rng=ci_rng)\n",
        "            ci_bias       = bootstrap_ci(df_n, model, 'bias_mean', B=B_use, rng=ci_rng)\n",
        "            ci_mse        = bootstrap_ci(df_n, model, 'mse_mean', B=B_use, rng=ci_rng)\n",
        "\n",
        "            summaries.append({\n",
        "                'n': int(n),\n",
        "                'model': model,\n",
        "                'avg_loglike_mean': float(summary.loc[summary['model'] == model, 'avg_loglike'].values[0]),\n",
        "                'avg_loglike_lo': ci_avgloglike[0],\n",
        "                'avg_loglike_hi': ci_avgloglike[1],\n",
        "                'tailks_mean': float(summary.loc[summary['model'] == model, 'tailks'].values[0]),\n",
        "                'tailks_lo': ci_tailks[0],\n",
        "                'tailks_hi': ci_tailks[1],\n",
        "                'bias_mean': float(summary.loc[summary['model'] == model, 'bias_mean'].values[0]),\n",
        "                'bias_lo': ci_bias[0],\n",
        "                'bias_hi': ci_bias[1],\n",
        "                'mse_mean': float(summary.loc[summary['model'] == model, 'mse_mean'].values[0]),\n",
        "                'mse_lo': ci_mse[0],\n",
        "                'mse_hi': ci_mse[1],\n",
        "            })\n",
        "\n",
        "            print(f\"\\n{model} (n={n}) 95% CI:\")\n",
        "            print(f\"  Avg LOGLIKE: {ci_avgloglike}\")\n",
        "            print(f\"  Tail KS   : {ci_tailks}\")\n",
        "            print(f\"  Bias      : {ci_bias}\")\n",
        "            print(f\"  MSE       : {ci_mse}\")\n",
        "\n",
        "        print(f\"Finished n={n} in {time.time() - t0:.1f}s\")\n",
        "\n",
        "    df_all = pd.concat(all_rows, ignore_index=True) if len(all_rows) > 0 else pd.DataFrame()\n",
        "    df_summary = pd.DataFrame(summaries)\n",
        "\n",
        "    csv_file = f\"{out_prefix}_summary.csv\"\n",
        "    tex_file = f\"{out_prefix}_summary.tex\"\n",
        "    df_summary.to_csv(csv_file, index=False)\n",
        "    try:\n",
        "        with open(tex_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(df_summary.to_latex(index=False, float_format=\"%.6f\"))\n",
        "    except Exception as e:\n",
        "        print(\"Warning: could not write LaTeX file:\", e)\n",
        "\n",
        "    print(f\"\\nSaved summary CSV to {csv_file} and LaTeX to {tex_file} (if no error).\")\n",
        "    return df_all, df_summary\n",
        "\n",
        "# ---------- Main ----------\n",
        "if __name__ == \"__main__\":\n",
        "    # 仅跑一次 n=2000（快速示例）。若要更稳定结果，请把 quick=False 并把 M, B_boot 调高。\n",
        "    df_all, df_summary = run_sample_size_sensitivity(\n",
        "        sample_sizes=[5000],\n",
        "        M=500,           # replication 数，真实研究建议 >=200-500\n",
        "        B_boot=500,     # bootstrap 次数，建议 >=500\n",
        "        seed=1234,\n",
        "        quick=False,    # quick=True 会把 M 和 B_boot 缩小为约1/10\n",
        "        mc_sample_size=20000,\n",
        "        out_prefix=\"mc_composite_n2000\"\n",
        "    )\n",
        "\n",
        "    print(\"\\nFinal summary:\")\n",
        "    print(df_summary)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Running Monte Carlo simulation with sample size 500 (M=50, B_boot=100)\n",
        "\n",
        "#Composite (n=500) 95% CI:\n",
        "#  Avg LOGLIKE: (1.0203065271887517, 1.0425575349824716)\n",
        "#  Tail KS   : (0.009981749999999996, 0.01109264999999999)\n",
        "#  Bias      : (0.061599514988977935, 0.07741750208248337)\n",
        "#  MSE       : (0.23937460912980368, 0.3048096085471503)\n",
        "\n",
        "#Skew-normal (n=500) 95% CI:\n",
        "#  Avg LOGLIKE: (-0.7403803231835338, -0.7020945558841764)\n",
        "#  Tail KS   : (0.06512174999999998, 0.08911767499999997)\n",
        "#  Bias      : (0.05227484264304224, 0.0788688540982724)\n",
        "#  MSE       : (0.25106083445145266, 0.2771680613256963)\n",
        "\n",
        "#Skew-t (n=500) 95% CI:\n",
        "#  Avg LOGLIKE: (0.18602374445674738, 0.23045145733729883)\n",
        "#  Tail KS   : (0.030686700000000004, 0.03213375)\n",
        "#  Bias      : (0.17429622197376368, 0.7717864156751897)\n",
        "#  MSE       : (36.180392310986164, 1741.1327376810939)\n",
        "#Finished n=500 in 12297.8s\n",
        "\n",
        "#Saved summary CSV to mc_composite_n2000_summary.csv and LaTeX to mc_composite_n2000_summary.tex (if no error).\n",
        "\n",
        "#Final summary:\n",
        "#     n        model  avg_loglike_mean  avg_loglike_lo  avg_loglike_hi  \\\n",
        "#0  500    Composite          1.031592        1.020307        1.042558\n",
        "#1  500  Skew-normal         -0.723335       -0.740380       -0.702095\n",
        "#2  500       Skew-t          0.209404        0.186024        0.230451\n",
        "\n",
        " #  tailks_mean  tailks_lo  tailks_hi  bias_mean   bias_lo   bias_hi  \\\n",
        "#0     0.010585   0.009982   0.011093   0.068968  0.061600  0.077418\n",
        "#1     0.076773   0.065122   0.089118   0.065245  0.052275  0.078869\n",
        "#2     0.031470   0.030687   0.032134   0.402457  0.174296  0.771786\n",
        "\n",
        " #    mse_mean     mse_lo       mse_hi\n",
        "#0    0.268879   0.239375     0.304810\n",
        "#1    0.263083   0.251061     0.277168\n",
        "#2  644.175063  36.180392  1741.132738"
      ],
      "metadata": {
        "id": "l3ihua9DPgOM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "5f2b1cd9-5466-4062-b083-68820497b405"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running Monte Carlo simulation with sample size 5000 (M=500, B_boot=500)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-677747566.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;31m# 仅跑一次 n=2000（快速示例）。若要更稳定结果，请把 quick=False 并把 M, B_boot 调高。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     df_all, df_summary = run_sample_size_sensitivity(\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0msample_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# replication 数，真实研究建议 >=200-500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-677747566.py\u001b[0m in \u001b[0;36mrun_sample_size_sensitivity\u001b[0;34m(sample_sizes, M, B_boot, seed, quick, mc_sample_size, out_prefix)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mrng_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_master\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m31\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mdf_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonte_carlo_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc_sample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmc_sample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mdf_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mall_rows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-677747566.py\u001b[0m in \u001b[0;36mmonte_carlo_sim\u001b[0;34m(M, n, seed, rng, mc_sample_size)\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mn_mid\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                             \u001b[0ma_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskewnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0ma_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, *args, **kwds)\u001b[0m\n\u001b[1;32m   9884\u001b[0m             \u001b[0;31m# At this point, parameter \"guesses\" may equal the fixed parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9885\u001b[0m             \u001b[0;31m# in kwds. No harm in passing them as guesses, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9886\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, *args, **kwds)\u001b[0m\n\u001b[1;32m   2757\u001b[0m         \u001b[0;31m# especially when the user fixes parameters. Minimizing the sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m         \u001b[0;31m# of squares of the error generalizes to these cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2759\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2760\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(func, x0, args, xtol, ftol, maxiter, maxfun, full_output, disp, retall, callback, initial_simplex)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mretlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fun'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nfev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbounds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m             \u001b[0mfxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m             \u001b[0mdoshrink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(x, *wrapper_args)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# A copy of x is sent to the user function (gh13740)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;31m# Ideally, we'd like to a have a true scalar returned from f(x). For\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# backwards-compatibility, also allow np.array([1.3]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_penalized_nnlf\u001b[0;34m(self, theta, x)\u001b[0m\n\u001b[1;32m   2440\u001b[0m             \u001b[0mn_log_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nnlf_and_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_log_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fitstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_nnlf_and_penalty\u001b[0;34m(self, x, args)\u001b[0m\n\u001b[1;32m   2416\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_bad\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margsreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mcond0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m             \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m         \u001b[0mtotals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_sum_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_logpdf\u001b[0;34m(self, x, a)\u001b[0m\n\u001b[1;32m   9705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9706\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_logpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9707\u001b[0;31m         return xpx.apply_where(\n\u001b[0m\u001b[1;32m   9708\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9709\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_norm_logpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/array_api_extra/_lib/_funcs.py\u001b[0m in \u001b[0;36mapply_where\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# map_blocks doesn't descend into tuples of Arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_apply_where\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_xp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/array_api_extra/_lib/_funcs.py\u001b[0m in \u001b[0;36m_apply_where\u001b[0;34m(cond, f1, f2, fill_value, xp, *args)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mncond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtemp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mncond\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, a)\u001b[0m\n\u001b[1;32m   9708\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9709\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_norm_logpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9710\u001b[0;31m             lambda x, a: np.log(2)+_norm_logpdf(x)+_norm_logcdf(a*x))\n\u001b[0m\u001b[1;32m   9711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9712\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_norm_logcdf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_norm_logcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_ndtr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# Monte Carlo Simulation (Composite, Fixed Thresholds, Parallel)\n",
        "\n",
        "# - theta1=-0.3, theta2=0.3 only\n",
        "# - M=500, B_boot=500\n",
        "# - Parallelized for faster computation\n",
        "# - Outputs CSV and LaTeX summary\n",
        "# \"\"\"\n",
        "\n",
        "# import time\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from scipy import stats\n",
        "# import warnings\n",
        "# from joblib import Parallel, delayed\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # ---------- RNG helper ----------\n",
        "# def ensure_rng(rs=None):\n",
        "#     if rs is None:\n",
        "#         return np.random.RandomState(None)\n",
        "#     if isinstance(rs, (int, np.integer)):\n",
        "#         return np.random.RandomState(int(rs))\n",
        "#     if isinstance(rs, np.random.RandomState):\n",
        "#         return rs\n",
        "#     return np.random.RandomState(None)\n",
        "\n",
        "# # ---------- Skew-t sampling ----------\n",
        "# def skewt_rvs(xi=0.0, omega=1.0, alpha=0.0, nu=6.0, size=1, random_state=None):\n",
        "#     rng = ensure_rng(random_state)\n",
        "#     U = stats.skewnorm.rvs(alpha, loc=0.0, scale=1.0, size=size, random_state=rng)\n",
        "#     S = rng.chisquare(nu, size=size)\n",
        "#     return xi + omega * U * np.sqrt(nu / S)\n",
        "\n",
        "# # ---------- Composite sampling ----------\n",
        "# def composite_rvs(size=1, xi=0.0, omega=1.0, alpha=15.0, nu=6.0,\n",
        "#                   theta1=-0.3, theta2=0.3, left_frac=0.08, right_frac=0.08, random_state=None):\n",
        "#     rng = ensure_rng(random_state)\n",
        "#     n = int(size)\n",
        "#     samples = np.empty(n, dtype=float)\n",
        "#     u = rng.rand(n)\n",
        "#     r1 = left_frac; r2 = right_frac\n",
        "#     comp = np.where(u < r1, 0, np.where(u < r1 + (1 - r1 - r2), 1, 2))\n",
        "\n",
        "#     for k in (0, 1, 2):\n",
        "#         idx = np.where(comp == k)[0]\n",
        "#         if idx.size == 0:\n",
        "#             continue\n",
        "#         need = idx.size\n",
        "#         draws = []\n",
        "#         while len(draws) < need:\n",
        "#             if k == 1:\n",
        "#                 batch = stats.skewnorm.rvs(alpha, loc=xi, scale=omega, size=max(need*2, 500), random_state=rng)\n",
        "#                 valid = batch[(batch > theta1) & (batch < theta2)]\n",
        "#             else:\n",
        "#                 batch = skewt_rvs(xi=xi, omega=omega, alpha=alpha, nu=nu, size=max(need*2, 500), random_state=rng)\n",
        "#                 if k == 0:\n",
        "#                     valid = batch[batch <= theta1]\n",
        "#                 else:\n",
        "#                     valid = batch[batch >= theta2]\n",
        "#             draws.extend(valid.tolist())\n",
        "#         samples[idx] = np.array(draws[:need])\n",
        "#     return samples\n",
        "\n",
        "# # ---------- Empirical CDF ----------\n",
        "# def empirical_cdf_factory(sample):\n",
        "#     s = np.sort(np.asarray(sample))\n",
        "#     n = len(s)\n",
        "#     def cdf(x):\n",
        "#         x = np.asarray(x)\n",
        "#         return np.searchsorted(s, x, side='right') / float(n)\n",
        "#     return cdf\n",
        "\n",
        "# # ---------- Tail KS ----------\n",
        "# def compute_tailks(cdf_func, data_sorted, upper_pct=95, lower_pct=5):\n",
        "#     lower_val = np.percentile(data_sorted, lower_pct)\n",
        "#     upper_val = np.percentile(data_sorted, upper_pct)\n",
        "#     tail_points = np.concatenate([data_sorted[data_sorted <= lower_val], data_sorted[data_sorted >= upper_val]])\n",
        "#     if len(tail_points) == 0:\n",
        "#         return np.nan\n",
        "#     fitted_vals = np.asarray(cdf_func(tail_points))\n",
        "#     n = len(data_sorted)\n",
        "#     empirical_vals = np.searchsorted(data_sorted, tail_points, side='right') / float(n)\n",
        "#     return float(np.max(np.abs(fitted_vals - empirical_vals)))\n",
        "\n",
        "# # ---------- Bootstrap CI (parallel) ----------\n",
        "# def bootstrap_ci(vals, B=500, alpha=0.05, rng_seed=None):\n",
        "#     rng = np.random.RandomState(rng_seed)\n",
        "#     n = len(vals)\n",
        "#     boot_means = Parallel(n_jobs=-1)(delayed(lambda r: np.mean(rng.choice(vals, size=n, replace=True)))(i) for i in range(B))\n",
        "#     lo = np.percentile(boot_means, 100*alpha/2)\n",
        "#     hi = np.percentile(boot_means, 100*(1-alpha/2))\n",
        "#     return float(lo), float(hi)\n",
        "\n",
        "# # ---------- Monte Carlo for one replication ----------\n",
        "# def monte_carlo_one(rep, n, mc_sample_size, seed=None):\n",
        "#     rng = np.random.RandomState(seed + rep if seed is not None else None)\n",
        "#     data = composite_rvs(size=n, theta1=-0.3, theta2=0.3, random_state=rng)\n",
        "#     data_sorted = np.sort(data)\n",
        "#     results = []\n",
        "\n",
        "#     for model_name in ['Composite', 'Skew-normal', 'Skew-t']:\n",
        "#         try:\n",
        "#             if model_name == 'Composite':\n",
        "#                 theta1, theta2 = -0.3, 0.3\n",
        "#                 left_obs = data[data <= theta1]\n",
        "#                 mid_obs = data[(data > theta1) & (data < theta2)]\n",
        "#                 right_obs = data[data >= theta2]\n",
        "\n",
        "#                 # fit skew-normal to center\n",
        "#                 if len(mid_obs) >= 10:\n",
        "#                     a_c, loc_c, scale_c = stats.skewnorm.fit(mid_obs)\n",
        "#                 else:\n",
        "#                     a_c, loc_c, scale_c = 15.0, 0.0, 1.0\n",
        "#                 # fit t to tails\n",
        "#                 df_l, loc_l, scale_l = stats.t.fit(left_obs) if len(left_obs)>=10 else (6.0, 0.0, 1.0)\n",
        "#                 df_r, loc_r, scale_r = stats.t.fit(right_obs) if len(right_obs)>=10 else (6.0, 0.0, 1.0)\n",
        "\n",
        "#                 # parametric sample\n",
        "#                 n_left_s = max(1, int(mc_sample_size*len(left_obs)/n))\n",
        "#                 n_mid_s = max(1, int(mc_sample_size*len(mid_obs)/n))\n",
        "#                 n_right_s = max(1, mc_sample_size - n_left_s - n_mid_s)\n",
        "\n",
        "#                 left_sample = stats.t.rvs(df_l, loc=loc_l, scale=scale_l, size=n_left_s, random_state=rng)\n",
        "#                 mid_sample = stats.skewnorm.rvs(a_c, loc=loc_c, scale=scale_c, size=n_mid_s, random_state=rng)\n",
        "#                 right_sample = stats.t.rvs(df_r, loc=loc_r, scale=scale_r, size=n_right_s, random_state=rng)\n",
        "#                 param_sample = np.concatenate([left_sample, mid_sample, right_sample])\n",
        "\n",
        "#                 ll_vals = np.empty_like(data)\n",
        "#                 ll_vals[data <= theta1] = stats.t.pdf(data[data <= theta1], df=df_l, loc=loc_l, scale=scale_l)\n",
        "#                 ll_vals[(data>theta1)&(data<theta2)] = stats.skewnorm.pdf(data[(data>theta1)&(data<theta2)], a=a_c, loc=loc_c, scale=scale_c)\n",
        "#                 ll_vals[data >= theta2] = stats.t.pdf(data[data >= theta2], df=df_r, loc=loc_r, scale=scale_r)\n",
        "#                 avg_loglike = float(np.mean(np.log(np.maximum(ll_vals,1e-12))))\n",
        "\n",
        "#             elif model_name == 'Skew-normal':\n",
        "#                 a_sn, loc_sn, scale_sn = stats.skewnorm.fit(data)\n",
        "#                 param_sample = stats.skewnorm.rvs(a_sn, loc=loc_sn, scale=scale_sn, size=mc_sample_size, random_state=rng)\n",
        "#                 avg_loglike = float(np.mean(stats.skewnorm.logpdf(data, a_sn, loc=loc_sn, scale=scale_sn)))\n",
        "\n",
        "#             else: # Skew-t\n",
        "#                 df_t, loc_t, scale_t = stats.t.fit(data)\n",
        "#                 param_sample = stats.t.rvs(df_t, loc=loc_t, scale=scale_t, size=mc_sample_size, random_state=rng)\n",
        "#                 avg_loglike = float(np.mean(stats.t.logpdf(data, df=df_t, loc=loc_t, scale=scale_t)))\n",
        "\n",
        "#             fitted_cdf = empirical_cdf_factory(param_sample)\n",
        "#             tailks = compute_tailks(fitted_cdf, data_sorted)\n",
        "#             sim_draw = rng.choice(param_sample, size=n, replace=False if len(param_sample)>=n else True)\n",
        "#             bias_mean = float(np.mean(sim_draw))\n",
        "#             mse_mean = float(np.mean((sim_draw - 0.0)**2))\n",
        "#         except Exception as e:\n",
        "#             avg_loglike, tailks, bias_mean, mse_mean = np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "#         results.append({'rep':rep, 'model':model_name, 'avg_loglike':avg_loglike,\n",
        "#                         'tailks':tailks, 'bias_mean':bias_mean, 'mse_mean':mse_mean})\n",
        "#     return results\n",
        "\n",
        "# # ---------- Run Monte Carlo ----------\n",
        "# def run_monte_carlo_parallel(n=500, M=500, B_boot=500, mc_sample_size=20000, seed=1234, out_prefix=\"mc_composite\"):\n",
        "#     t0 = time.time()\n",
        "#     print(f\"Running Monte Carlo: n={n}, M={M}, B_boot={B_boot}\")\n",
        "\n",
        "#     all_results = Parallel(n_jobs=-1)(delayed(monte_carlo_one)(rep, n, mc_sample_size, seed) for rep in range(M))\n",
        "#     df_all = pd.DataFrame([r for sublist in all_results for r in sublist])\n",
        "\n",
        "#     # compute bootstrap CI per model\n",
        "#     summaries = []\n",
        "#     for model in df_all['model'].unique():\n",
        "#         df_model = df_all[df_all['model']==model]\n",
        "#         ci_rng_seed = seed\n",
        "#         avg_loglike_lo, avg_loglike_hi = bootstrap_ci(df_model['avg_loglike'].values, B=B_boot, rng_seed=ci_rng_seed)\n",
        "#         tailks_lo, tailks_hi = bootstrap_ci(df_model['tailks'].values, B=B_boot, rng_seed=ci_rng_seed+1)\n",
        "#         bias_lo, bias_hi = bootstrap_ci(df_model['bias_mean'].values, B=B_boot, rng_seed=ci_rng_seed+2)\n",
        "#         mse_lo, mse_hi = bootstrap_ci(df_model['mse_mean'].values, B=B_boot, rng_seed=ci_rng_seed+3)\n",
        "\n",
        "#         summaries.append({\n",
        "#             'n': n,\n",
        "#             'model': model,\n",
        "#             'avg_loglike_mean': df_model['avg_loglike'].mean(),\n",
        "#             'avg_loglike_lo': avg_loglike_lo,\n",
        "#             'avg_loglike_hi': avg_loglike_hi,\n",
        "#             'tailks_mean': df_model['tailks'].mean(),\n",
        "#             'tailks_lo': tailks_lo,\n",
        "#             'tailks_hi': tailks_hi,\n",
        "#             'bias_mean': df_model['bias_mean'].mean(),\n",
        "#             'bias_lo': bias_lo,\n",
        "#             'bias_hi': bias_hi,\n",
        "#             'mse_mean': df_model['mse_mean'].mean(),\n",
        "#             'mse_lo': mse_lo,\n",
        "#             'mse_hi': mse_hi\n",
        "#         })\n",
        "#         print(f\"\\n{model} (n={n}) 95% CI:\")\n",
        "#         print(f\"  Avg LOGLIKE: ({avg_loglike_lo:.6f}, {avg_loglike_hi:.6f})\")\n",
        "#         print(f\"  Tail KS   : ({tailks_lo:.6f}, {tailks_hi:.6f})\")\n",
        "#         print(f\"  Bias      : ({bias_lo:.6f}, {bias_hi:.6f})\")\n",
        "#         print(f\"  MSE       : ({mse_lo:.6f}, {mse_hi:.6f})\")\n",
        "\n",
        "#     df_summary = pd.DataFrame(summaries)\n",
        "#     csv_file = f\"{out_prefix}_summary.csv\"\n",
        "#     tex_file = f\"{out_prefix}_summary.tex\"\n",
        "#     df_summary.to_csv(csv_file, index=False)\n",
        "#     with open(tex_file, \"w\", encoding=\"utf-8\") as f:\n",
        "#         f.write(df_summary.to_latex(index=False, float_format=\"%.6f\"))\n",
        "\n",
        "#     print(f\"\\nFinished Monte Carlo in {time.time()-t0:.1f}s\")\n",
        "#     print(f\"Saved summary CSV to {csv_file} and LaTeX to {tex_file}\")\n",
        "#     return df_all, df_summary\n",
        "\n",
        "# # ---------- Main ----------\n",
        "# if __name__ == \"__main__\":\n",
        "#     df_all, df_summary = run_monte_carlo_parallel(n=5000, M=200, B_boot=500, mc_sample_size=20000, seed=1234)\n",
        "#     print(\"\\nFinal summary:\")\n",
        "#     print(df_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKTenPFFJe71",
        "outputId": "11e69ea4-fbe9-4ee6-a5e4-88efd7c57cc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Monte Carlo: n=5000, M=200, B_boot=500\n",
            "\n",
            "Composite (n=5000) 95% CI:\n",
            "  Avg LOGLIKE: (0.819865, 0.823289)\n",
            "  Tail KS   : (0.007623, 0.008518)\n",
            "  Bias      : (0.175823, 0.177596)\n",
            "  MSE       : (0.169777, 0.188341)\n",
            "\n",
            "Skew-normal (n=5000) 95% CI:\n",
            "  Avg LOGLIKE: (-0.321716, -0.312322)\n",
            "  Tail KS   : (0.033702, 0.036747)\n",
            "  Bias      : (0.223033, 0.225862)\n",
            "  MSE       : (0.172196, 0.175756)\n",
            "\n",
            "Skew-t (n=5000) 95% CI:\n",
            "  Avg LOGLIKE: (0.119527, 0.123650)\n",
            "  Tail KS   : (0.022955, 0.023537)\n",
            "  Bias      : (0.146862, 0.160341)\n",
            "  MSE       : (2.258317, 27.070876)\n",
            "\n",
            "Finished Monte Carlo in 560.5s\n",
            "Saved summary CSV to mc_composite_summary.csv and LaTeX to mc_composite_summary.tex\n",
            "\n",
            "Final summary:\n",
            "      n        model  avg_loglike_mean  avg_loglike_lo  avg_loglike_hi  \\\n",
            "0  5000    Composite          0.821257        0.819865        0.823289   \n",
            "1  5000  Skew-normal         -0.317281       -0.321716       -0.312322   \n",
            "2  5000       Skew-t          0.121917        0.119527        0.123650   \n",
            "\n",
            "   tailks_mean  tailks_lo  tailks_hi  bias_mean   bias_lo   bias_hi  \\\n",
            "0     0.007959   0.007623   0.008518   0.176751  0.175823  0.177596   \n",
            "1     0.035421   0.033702   0.036747   0.224491  0.223033  0.225862   \n",
            "2     0.023201   0.022955   0.023537   0.152661  0.146862  0.160341   \n",
            "\n",
            "    mse_mean    mse_lo     mse_hi  \n",
            "0   0.177716  0.169777   0.188341  \n",
            "1   0.174468  0.172196   0.175756  \n",
            "2  11.284205  2.258317  27.070876  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Monte Carlo Simulation (Composite, Skew-normal, Skew-t, Parallel)\n",
        "for large n M B\n",
        "- theta1=-0.3, theta2=0.3 only\n",
        "- M=500, B_boot=500\n",
        "- Parallelized for faster computation\n",
        "- Outputs CSV and LaTeX summary\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from joblib import Parallel, delayed\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ---------- RNG helper ----------\n",
        "def ensure_rng(rs=None):\n",
        "    if rs is None:\n",
        "        return np.random.RandomState(None)\n",
        "    if isinstance(rs, (int, np.integer)):\n",
        "        return np.random.RandomState(int(rs))\n",
        "    if isinstance(rs, np.random.RandomState):\n",
        "        return rs\n",
        "    return np.random.RandomState(None)\n",
        "\n",
        "# ---------- Composite sampling ----------\n",
        "def composite_rvs(size=1, theta1=-0.3, theta2=0.3, left_frac=0.08, right_frac=0.08, random_state=None):\n",
        "    rng = ensure_rng(random_state)\n",
        "    n = int(size)\n",
        "    samples = np.empty(n, dtype=float)\n",
        "    u = rng.rand(n)\n",
        "    r1, r2 = left_frac, right_frac\n",
        "    comp = np.where(u < r1, 0, np.where(u < 1-r2, 1, 2))\n",
        "    for k in (0,1,2):\n",
        "        idx = np.where(comp==k)[0]\n",
        "        if idx.size==0: continue\n",
        "        need = idx.size\n",
        "        draws = []\n",
        "        while len(draws)<need:\n",
        "            if k==1:\n",
        "                batch = stats.uniform.rvs(loc=theta1, scale=theta2-theta1, size=max(need*2,500), random_state=rng)\n",
        "                valid = batch[(batch>theta1) & (batch<theta2)]\n",
        "            else:\n",
        "                batch = stats.t.rvs(df=6, loc=0, scale=1, size=max(need*2,500), random_state=rng)\n",
        "                valid = batch[batch<=theta1] if k==0 else batch[batch>=theta2]\n",
        "            draws.extend(valid.tolist())\n",
        "        samples[idx] = np.array(draws[:need])\n",
        "    return samples\n",
        "\n",
        "# ---------- Empirical CDF ----------\n",
        "def empirical_cdf_factory(sample):\n",
        "    s = np.sort(np.asarray(sample))\n",
        "    n = len(s)\n",
        "    def cdf(x):\n",
        "        x = np.asarray(x)\n",
        "        return np.searchsorted(s, x, side='right')/float(n)\n",
        "    return cdf\n",
        "\n",
        "# ---------- Tail KS ----------\n",
        "def compute_tailks(cdf_func, data_sorted, upper_pct=95, lower_pct=5):\n",
        "    lower_val = np.percentile(data_sorted, lower_pct)\n",
        "    upper_val = np.percentile(data_sorted, upper_pct)\n",
        "    tail_points = np.concatenate([data_sorted[data_sorted<=lower_val], data_sorted[data_sorted>=upper_val]])\n",
        "    if len(tail_points)==0: return np.nan\n",
        "    fitted_vals = np.asarray(cdf_func(tail_points))\n",
        "    n = len(data_sorted)\n",
        "    empirical_vals = np.searchsorted(data_sorted, tail_points, side='right')/float(n)\n",
        "    return float(np.max(np.abs(fitted_vals-empirical_vals)))\n",
        "\n",
        "# ---------- Bootstrap CI ----------\n",
        "def bootstrap_ci(vals, B=500, alpha=0.05, rng_seed=None):\n",
        "    rng = np.random.RandomState(rng_seed)\n",
        "    n = len(vals)\n",
        "    boot_means = Parallel(n_jobs=-1)(delayed(lambda i: np.mean(rng.choice(vals, size=n, replace=True)))(i) for i in range(B))\n",
        "    lo = np.percentile(boot_means, 100*alpha/2)\n",
        "    hi = np.percentile(boot_means, 100*(1-alpha/2))\n",
        "    return float(lo), float(hi)\n",
        "\n",
        "# ---------- One Monte Carlo replication ----------\n",
        "def monte_carlo_one(rep, n, mc_sample_size, seed=None):\n",
        "    rng = np.random.RandomState(seed+rep if seed is not None else None)\n",
        "    data = composite_rvs(size=n, theta1=-0.3, theta2=0.3, random_state=rng)\n",
        "    data_sorted = np.sort(data)\n",
        "    results = []\n",
        "\n",
        "    for model_name in ['Composite','Skew-normal','Skew-t']:\n",
        "        try:\n",
        "            if model_name=='Composite':\n",
        "                theta1,theta2=-0.3,0.3\n",
        "                left_obs = data[data<=theta1]\n",
        "                mid_obs = data[(data>theta1)&(data<theta2)]\n",
        "                right_obs = data[data>=theta2]\n",
        "                # fit skew-normal for center\n",
        "                if len(mid_obs)>=10:\n",
        "                    a_c, loc_c, scale_c = stats.skewnorm.fit(mid_obs)\n",
        "                else:\n",
        "                    a_c, loc_c, scale_c = 0.0,0.0,1.0\n",
        "                # fit t for tails\n",
        "                df_l, loc_l, scale_l = stats.t.fit(left_obs) if len(left_obs)>=10 else (6.0,0.0,1.0)\n",
        "                df_r, loc_r, scale_r = stats.t.fit(right_obs) if len(right_obs)>=10 else (6.0,0.0,1.0)\n",
        "                # parametric sample\n",
        "                n_left_s = max(1,int(mc_sample_size*len(left_obs)/n))\n",
        "                n_mid_s = max(1,int(mc_sample_size*len(mid_obs)/n))\n",
        "                n_right_s = max(1,mc_sample_size-n_left_s-n_mid_s)\n",
        "                left_sample = stats.t.rvs(df_l, loc=loc_l, scale=scale_l, size=n_left_s, random_state=rng)\n",
        "                mid_sample = stats.skewnorm.rvs(a_c, loc=loc_c, scale=scale_c, size=n_mid_s, random_state=rng)\n",
        "                right_sample = stats.t.rvs(df_r, loc=loc_r, scale=scale_r, size=n_right_s, random_state=rng)\n",
        "                param_sample = np.concatenate([left_sample,mid_sample,right_sample])\n",
        "                # log-likelihood\n",
        "                ll_vals = np.empty_like(data)\n",
        "                ll_vals[data<=theta1] = stats.t.pdf(data[data<=theta1], df=df_l, loc=loc_l, scale=scale_l)\n",
        "                ll_vals[(data>theta1)&(data<theta2)] = stats.skewnorm.pdf(data[(data>theta1)&(data<theta2)], a_c, loc_c, scale_c)\n",
        "                ll_vals[data>=theta2] = stats.t.pdf(data[data>=theta2], df=df_r, loc=loc_r, scale=scale_r)\n",
        "                avg_loglike = float(np.mean(np.log(np.maximum(ll_vals,1e-12))))\n",
        "            elif model_name=='Skew-normal':\n",
        "                a_sn, loc_sn, scale_sn = stats.skewnorm.fit(data)\n",
        "                param_sample = stats.skewnorm.rvs(a_sn, loc=loc_sn, scale=scale_sn, size=mc_sample_size, random_state=rng)\n",
        "                avg_loglike = float(np.mean(stats.skewnorm.logpdf(data, a_sn, loc_sn, scale_sn)))\n",
        "            else: # Skew-t\n",
        "                df_t, loc_t, scale_t = stats.t.fit(data)\n",
        "                param_sample = stats.t.rvs(df_t, loc=loc_t, scale=scale_t, size=mc_sample_size, random_state=rng)\n",
        "                avg_loglike = float(np.mean(stats.t.logpdf(data, df=df_t, loc=loc_t, scale=scale_t)))\n",
        "\n",
        "            fitted_cdf = empirical_cdf_factory(param_sample)\n",
        "            tailks = compute_tailks(fitted_cdf, data_sorted)\n",
        "            sim_draw = rng.choice(param_sample, size=n, replace=False if len(param_sample)>=n else True)\n",
        "            bias_mean = float(np.mean(sim_draw))\n",
        "            mse_mean = float(np.mean((sim_draw-0.0)**2))\n",
        "        except:\n",
        "            avg_loglike, tailks, bias_mean, mse_mean = np.nan,np.nan,np.nan,np.nan\n",
        "        results.append({'rep':rep,'model':model_name,'avg_loglike':avg_loglike,\n",
        "                        'tailks':tailks,'bias_mean':bias_mean,'mse_mean':mse_mean})\n",
        "    return results\n",
        "\n",
        "# ---------- Run Monte Carlo ----------\n",
        "def run_monte_carlo_parallel(n=5000, M=500, B_boot=500, mc_sample_size=20000, seed=1234, out_prefix=\"mc_composite\"):\n",
        "    t0 = time.time()\n",
        "    print(f\"Running Monte Carlo: n={n}, M={M}, B_boot={B_boot}\")\n",
        "    all_results = Parallel(n_jobs=-1)(delayed(monte_carlo_one)(rep,n,mc_sample_size,seed) for rep in range(M))\n",
        "    df_all = pd.DataFrame([r for sublist in all_results for r in sublist])\n",
        "    # compute bootstrap CI per model\n",
        "    summaries = []\n",
        "    for model in df_all['model'].unique():\n",
        "        df_model = df_all[df_all['model']==model]\n",
        "        avg_loglike_lo, avg_loglike_hi = bootstrap_ci(df_model['avg_loglike'].values, B=B_boot, rng_seed=seed)\n",
        "        tailks_lo, tailks_hi = bootstrap_ci(df_model['tailks'].values, B=B_boot, rng_seed=seed+1)\n",
        "        bias_lo, bias_hi = bootstrap_ci(df_model['bias_mean'].values, B=B_boot, rng_seed=seed+2)\n",
        "        mse_lo, mse_hi = bootstrap_ci(df_model['mse_mean'].values, B=B_boot, rng_seed=seed+3)\n",
        "        summaries.append({\n",
        "            'n': n, 'model': model,\n",
        "            'avg_loglike_mean': df_model['avg_loglike'].mean(),\n",
        "            'avg_loglike_lo': avg_loglike_lo,\n",
        "            'avg_loglike_hi': avg_loglike_hi,\n",
        "            'tailks_mean': df_model['tailks'].mean(),\n",
        "            'tailks_lo': tailks_lo,\n",
        "            'tailks_hi': tailks_hi,\n",
        "            'bias_mean': df_model['bias_mean'].mean(),\n",
        "            'bias_lo': bias_lo,\n",
        "            'bias_hi': bias_hi,\n",
        "            'mse_mean': df_model['mse_mean'].mean(),\n",
        "            'mse_lo': mse_lo,\n",
        "            'mse_hi': mse_hi\n",
        "        })\n",
        "        print(f\"\\n{model} (n={n}) 95% CI:\")\n",
        "        print(f\"  Avg LOGLIKE: ({avg_loglike_lo:.6f}, {avg_loglike_hi:.6f})\")\n",
        "        print(f\"  Tail KS   : ({tailks_lo:.6f}, {tailks_hi:.6f})\")\n",
        "        print(f\"  Bias      : ({bias_lo:.6f}, {bias_hi:.6f})\")\n",
        "        print(f\"  MSE       : ({mse_lo:.6f}, {mse_hi:.6f})\")\n",
        "\n",
        "    df_summary = pd.DataFrame(summaries)\n",
        "    csv_file = f\"{out_prefix}_summary.csv\"\n",
        "    tex_file = f\"{out_prefix}_summary.tex\"\n",
        "    df_summary.to_csv(csv_file,index=False)\n",
        "    with open(tex_file,\"w\",encoding=\"utf-8\") as f:\n",
        "        f.write(df_summary.to_latex(index=False,float_format=\"%.6f\"))\n",
        "    print(f\"\\nFinished Monte Carlo in {time.time()-t0:.1f}s\")\n",
        "    print(f\"Saved summary CSV to {csv_file} and LaTeX to {tex_file}\")\n",
        "    return df_all, df_summary\n",
        "\n",
        "# ---------- Main ----------\n",
        "if __name__==\"__main__\":\n",
        "    df_all, df_summary = run_monte_carlo_parallel(n=5000, M=500, B_boot=500, mc_sample_size=20000, seed=1234)\n",
        "    print(\"\\nFinal summary:\")\n",
        "    print(df_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCXDr3k9O0p7",
        "outputId": "b2c785b6-85b7-40e1-a909-f51fdadbba5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Monte Carlo: n=5000, M=500, B_boot=500\n",
            "\n",
            "Composite (n=5000) 95% CI:\n",
            "  Avg LOGLIKE: (0.110033, 0.112461)\n",
            "  Tail KS   : (0.006635, 0.006803)\n",
            "  Bias      : (-0.000970, 0.000582)\n",
            "  MSE       : (0.284660, 0.294595)\n",
            "\n",
            "Skew-normal (n=5000) 95% CI:\n",
            "  Avg LOGLIKE: (-0.863804, -0.856924)\n",
            "  Tail KS   : (0.052294, 0.054251)\n",
            "  Bias      : (-0.001483, 0.000946)\n",
            "  MSE       : (0.327104, 0.330715)\n",
            "\n",
            "Skew-t (n=5000) 95% CI:\n",
            "  Avg LOGLIKE: (-0.408264, -0.403928)\n",
            "  Tail KS   : (0.015666, 0.015915)\n",
            "  Bias      : (-0.002386, 0.002377)\n",
            "  MSE       : (1.500749, 7.261746)\n",
            "\n",
            "Finished Monte Carlo in 244.2s\n",
            "Saved summary CSV to mc_composite_summary.csv and LaTeX to mc_composite_summary.tex\n",
            "\n",
            "Final summary:\n",
            "      n        model  avg_loglike_mean  avg_loglike_lo  avg_loglike_hi  \\\n",
            "0  5000    Composite          0.111351        0.110033        0.112461   \n",
            "1  5000  Skew-normal         -0.859650       -0.863804       -0.856924   \n",
            "2  5000       Skew-t         -0.405693       -0.408264       -0.403928   \n",
            "\n",
            "   tailks_mean  tailks_lo  tailks_hi  bias_mean   bias_lo   bias_hi  mse_mean  \\\n",
            "0     0.006713   0.006635   0.006803  -0.000093 -0.000970  0.000582  0.288681   \n",
            "1     0.053646   0.052294   0.054251  -0.000466 -0.001483  0.000946  0.328907   \n",
            "2     0.015774   0.015666   0.015915   0.000133 -0.002386  0.002377  4.216216   \n",
            "\n",
            "     mse_lo    mse_hi  \n",
            "0  0.284660  0.294595  \n",
            "1  0.327104  0.330715  \n",
            "2  1.500749  7.261746  \n"
          ]
        }
      ]
    }
  ]
}