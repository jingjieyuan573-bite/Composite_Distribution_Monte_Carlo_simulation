{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYAQ33MpcdzuGOEaCME3mk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jingjieyuan573-bite/Composite_Distribution_analysis/blob/main/Composite_Monte_Threshold_Sensitivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Composite Monte Carlo Simulation (Fixed thresholds)\n",
        "\n",
        "- Runs for four fixed thresholds: Baseline, Lower, Higher, Extreme\n",
        "- Computes Bias, MSE, Avg LOGLIKE, Tail KS with 95% bootstrap CI\n",
        "- Prints results in aligned table form\n",
        "- Saves summary CSV and LaTeX\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ---------- RNG helper ----------\n",
        "def ensure_rng(rs=None):\n",
        "    if rs is None:\n",
        "        return np.random.RandomState(None)\n",
        "    if isinstance(rs, (int, np.integer)):\n",
        "        return np.random.RandomState(int(rs))\n",
        "    if isinstance(rs, np.random.RandomState):\n",
        "        return rs\n",
        "    return np.random.RandomState(None)\n",
        "\n",
        "# ---------- Composite sampling ----------\n",
        "def composite_rvs(size=1, theta1=-0.3, theta2=0.3, left_frac=0.08, right_frac=0.08, random_state=None):\n",
        "    rng = ensure_rng(random_state)\n",
        "    n = int(size)\n",
        "    samples = np.empty(n, dtype=float)\n",
        "    u = rng.rand(n)\n",
        "    r1 = left_frac; r2 = right_frac\n",
        "    comp = np.where(u < r1, 0, np.where(u < r1 + (1 - r1 - r2), 1, 2))\n",
        "\n",
        "    for k in (0, 1, 2):\n",
        "        idx = np.where(comp == k)[0]\n",
        "        if idx.size == 0:\n",
        "            continue\n",
        "        need = idx.size\n",
        "        draws = []\n",
        "        while len(draws) < need:\n",
        "            if k == 1:\n",
        "                batch = stats.uniform.rvs(loc=theta1, scale=theta2-theta1, size=max(need*2, 500), random_state=rng)\n",
        "                valid = batch[(batch > theta1) & (batch < theta2)]\n",
        "            else:\n",
        "                batch = stats.norm.rvs(loc=0, scale=1, size=max(need*2, 500), random_state=rng)\n",
        "                if k == 0:\n",
        "                    valid = batch[batch <= theta1]\n",
        "                else:\n",
        "                    valid = batch[batch >= theta2]\n",
        "            draws.extend(valid.tolist())\n",
        "        samples[idx] = np.array(draws[:need])\n",
        "    return samples\n",
        "\n",
        "# ---------- Empirical CDF ----------\n",
        "def empirical_cdf_factory(sample):\n",
        "    s = np.sort(np.asarray(sample))\n",
        "    n = len(s)\n",
        "    def cdf(x):\n",
        "        x = np.asarray(x)\n",
        "        return np.searchsorted(s, x, side='right') / float(n)\n",
        "    return cdf\n",
        "\n",
        "# ---------- Tail KS ----------\n",
        "def compute_tailks(cdf_func, data_sorted, upper_pct, lower_pct):\n",
        "    lower_val = np.percentile(data_sorted, lower_pct)\n",
        "    upper_val = np.percentile(data_sorted, upper_pct)\n",
        "    tail_points = np.concatenate([data_sorted[data_sorted <= lower_val], data_sorted[data_sorted >= upper_val]])\n",
        "    if len(tail_points) == 0:\n",
        "        return np.nan\n",
        "    fitted_vals = np.asarray(cdf_func(tail_points))\n",
        "    n = len(data_sorted)\n",
        "    empirical_vals = np.searchsorted(data_sorted, tail_points, side='right') / float(n)\n",
        "    return float(np.max(np.abs(fitted_vals - empirical_vals)))\n",
        "\n",
        "# ---------- Monte Carlo per threshold ----------\n",
        "def monte_carlo_sim(M=50, n=2000, theta1=-0.3, theta2=0.3, mc_sample_size=20000, seed=None):\n",
        "    rng = ensure_rng(seed)\n",
        "    rows = []\n",
        "\n",
        "    for rep in range(int(M)):\n",
        "        data = composite_rvs(size=n, theta1=theta1, theta2=theta2, random_state=rng)\n",
        "        data_sorted = np.sort(data)\n",
        "\n",
        "        # Fit composite \"model\" by region\n",
        "        n_left = np.sum(data <= theta1)\n",
        "        n_mid = np.sum((data > theta1) & (data < theta2))\n",
        "        n_right = np.sum(data >= theta2)\n",
        "\n",
        "        # Create parametric sample for estimated CDF\n",
        "        n_left_s = max(1, int(mc_sample_size * n_left / n))\n",
        "        n_mid_s = max(1, int(mc_sample_size * n_mid / n))\n",
        "        n_right_s = max(1, mc_sample_size - n_left_s - n_mid_s)\n",
        "\n",
        "        left_sample = stats.norm.rvs(loc=0, scale=1, size=n_left_s, random_state=rng)\n",
        "        mid_sample = stats.uniform.rvs(loc=theta1, scale=theta2-theta1, size=n_mid_s, random_state=rng)\n",
        "        right_sample = stats.norm.rvs(loc=0, scale=1, size=n_right_s, random_state=rng)\n",
        "\n",
        "        param_sample = np.concatenate([left_sample, mid_sample, right_sample])\n",
        "        fitted_cdf = empirical_cdf_factory(param_sample)\n",
        "        tailks = compute_tailks(fitted_cdf, data_sorted, 95, 5)\n",
        "\n",
        "        sim_draw = rng.choice(param_sample, size=n, replace=True)\n",
        "        bias_mean = float(np.mean(sim_draw))\n",
        "        mse_mean = float(np.mean((sim_draw - 0.0)**2))\n",
        "        avg_loglike = float(np.mean(np.log(np.maximum(fitted_cdf(data), 1e-12))))\n",
        "\n",
        "        rows.append({'rep': rep, 'model': 'Composite',\n",
        "                     'avg_loglike': avg_loglike,\n",
        "                     'tailks': tailks,\n",
        "                     'bias_mean': bias_mean,\n",
        "                     'mse_mean': mse_mean})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Bootstrap CI ----------\n",
        "def bootstrap_ci(df, model, col, B=500, alpha=0.05, rng=None):\n",
        "    rng = ensure_rng(rng)\n",
        "    vals = df[df['model'] == model][col].values\n",
        "    n = len(vals)\n",
        "    if n == 0:\n",
        "        return (np.nan, np.nan)\n",
        "    boot_means = [np.mean(rng.choice(vals, size=n, replace=True)) for _ in range(int(B))]\n",
        "    lo = np.percentile(boot_means, 100*alpha/2)\n",
        "    hi = np.percentile(boot_means, 100*(1-alpha/2))\n",
        "    return float(lo), float(hi)\n",
        "\n",
        "# ---------- Threshold wrapper ----------\n",
        "def threshold_sensitivity_composite(thresholds, n=2000, M=50, B_boot=100, seed=1234, mc_sample_size=20000,\n",
        "                                    out_prefix=\"threshold_composite_results\"):\n",
        "    rng_master = ensure_rng(seed)\n",
        "    summaries = []\n",
        "    rows_all = []\n",
        "\n",
        "    for th in thresholds:\n",
        "        t0 = time.time()\n",
        "        print(f\"\\nRunning threshold '{th['label']}': theta1={th['theta1']}, theta2={th['theta2']} (n={n}, M={M}, B={B_boot})\")\n",
        "        rng_n = ensure_rng(rng_master.randint(2**31 - 1))\n",
        "\n",
        "        df_n = monte_carlo_sim(M=M, n=n, theta1=th['theta1'], theta2=th['theta2'],\n",
        "                               seed=None, mc_sample_size=mc_sample_size)\n",
        "        df_n['threshold_label'] = th['label']\n",
        "        df_n['theta1'] = th['theta1']\n",
        "        df_n['theta2'] = th['theta2']\n",
        "        rows_all.append(df_n)\n",
        "\n",
        "        df_comp = df_n[df_n['model']=='Composite']\n",
        "        mean_avglog = df_comp['avg_loglike'].mean()\n",
        "        mean_tailks = df_comp['tailks'].mean()\n",
        "        mean_bias = df_comp['bias_mean'].mean()\n",
        "        mean_mse = df_comp['mse_mean'].mean()\n",
        "\n",
        "        ci_rng = ensure_rng(rng_n.randint(2**31 - 1))\n",
        "        avglog_lo, avglog_hi = bootstrap_ci(df_n, 'Composite', 'avg_loglike', B=B_boot, rng=ci_rng)\n",
        "        tailks_lo, tailks_hi = bootstrap_ci(df_n, 'Composite', 'tailks', B=B_boot, rng=ci_rng)\n",
        "        bias_lo, bias_hi = bootstrap_ci(df_n, 'Composite', 'bias_mean', B=B_boot, rng=ci_rng)\n",
        "        mse_lo, mse_hi = bootstrap_ci(df_n, 'Composite', 'mse_mean', B=B_boot, rng=ci_rng)\n",
        "\n",
        "        summaries.append({\n",
        "            'threshold_label': th['label'],\n",
        "            'theta1': th['theta1'],\n",
        "            'theta2': th['theta2'],\n",
        "            'avglog_mean': mean_avglog, 'avglog_lo': avglog_lo, 'avglog_hi': avglog_hi,\n",
        "            'tailks_mean': mean_tailks, 'tailks_lo': tailks_lo, 'tailks_hi': tailks_hi,\n",
        "            'bias_mean': mean_bias, 'bias_lo': bias_lo, 'bias_hi': bias_hi,\n",
        "            'mse_mean': mean_mse, 'mse_lo': mse_lo, 'mse_hi': mse_hi\n",
        "        })\n",
        "\n",
        "        # ---------- Print in aligned style ----------\n",
        "        print(f\"Composite ({th['label']}) 95% CI:\")\n",
        "        print(f\"  Avg LOGLIKE: ({avglog_lo}, {avglog_hi})\")\n",
        "        print(f\"  Tail KS   : ({tailks_lo}, {tailks_hi})\")\n",
        "        print(f\"  Bias      : ({bias_lo}, {bias_hi})\")\n",
        "        print(f\"  MSE       : ({mse_lo}, {mse_hi})\")\n",
        "        print(f\"Finished {th['label']} in {time.time()-t0:.1f}s\")\n",
        "\n",
        "    df_all = pd.concat(rows_all, ignore_index=True)\n",
        "    df_summary = pd.DataFrame(summaries)\n",
        "\n",
        "    # ---------- Save CSV ----------\n",
        "    csv_file = f\"{out_prefix}_composite_thresholds_summary.csv\"\n",
        "    df_summary.to_csv(csv_file, index=False)\n",
        "\n",
        "    # ---------- Save LaTeX ----------\n",
        "    tex_file = f\"{out_prefix}_composite_thresholds_summary.tex\"\n",
        "    try:\n",
        "        with open(tex_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(df_summary.to_latex(index=False, float_format=\"%.6f\"))\n",
        "    except Exception as e:\n",
        "        print(\"Warning: could not write LaTeX file:\", e)\n",
        "\n",
        "    print(f\"\\nSaved CSV to {csv_file} and LaTeX to {tex_file} (if no error).\")\n",
        "\n",
        "    # ---------- Print full summary table ----------\n",
        "    print(\"\\nThreshold sensitivity summary (Composite only):\")\n",
        "    # Align columns nicely\n",
        "    col_order = ['threshold_label', 'theta1', 'theta2',\n",
        "                 'avglog_mean', 'avglog_lo', 'avglog_hi',\n",
        "                 'tailks_mean', 'tailks_lo', 'tailks_hi',\n",
        "                 'bias_mean', 'bias_lo', 'bias_hi',\n",
        "                 'mse_mean', 'mse_lo', 'mse_hi']\n",
        "    print(df_summary[col_order].to_string(index=False, float_format=\"%.6f\"))\n",
        "    return df_all, df_summary\n",
        "\n",
        "# ---------- Main ----------\n",
        "if __name__ == \"__main__\":\n",
        "    thresholds = [\n",
        "        {'theta1': -0.3, 'theta2': 0.3, 'label': 'Baseline'},\n",
        "        {'theta1': -1.0, 'theta2': 0.2, 'label': 'Lower'},\n",
        "        {'theta1': -0.2, 'theta2': 1.0, 'label': 'Higher'},\n",
        "        {'theta1': -2.0, 'theta2': 2.0, 'label': 'Extreme'}\n",
        "    ]\n",
        "\n",
        "    df_all, df_summary = threshold_sensitivity_composite(\n",
        "        thresholds,\n",
        "        n=2000,\n",
        "        M=50,\n",
        "        B_boot=100,\n",
        "        seed=1234,\n",
        "        mc_sample_size=20000,\n",
        "        out_prefix=\"threshold_composite_results\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMJUDfF5Qv1k",
        "outputId": "1a717d12-ada3-458f-aaf3-c244b7ecc92f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running threshold 'Baseline': theta1=-0.3, theta2=0.3 (n=2000, M=50, B=100)\n",
            "Composite (Baseline) 95% CI:\n",
            "  Avg LOGLIKE: (-1.0398103048605658, -1.0293002942761744)\n",
            "  Tail KS   : (0.013627500000000006, 0.014708150000000005)\n",
            "  Bias      : (-0.0008430394612083925, 0.005624549347923798)\n",
            "  MSE       : (0.18081600710600518, 0.18844987016737352)\n",
            "Finished Baseline in 0.2s\n",
            "\n",
            "Running threshold 'Lower': theta1=-1.0, theta2=0.2 (n=2000, M=50, B=100)\n",
            "Composite (Lower) 95% CI:\n",
            "  Avg LOGLIKE: (-1.208265932797394, -1.1928596444869954)\n",
            "  Tail KS   : (0.033753875, 0.034639025000000004)\n",
            "  Bias      : (-0.338940525538692, -0.33227448157096556)\n",
            "  MSE       : (0.3902579554522684, 0.3990323971617788)\n",
            "Finished Lower in 0.2s\n",
            "\n",
            "Running threshold 'Higher': theta1=-0.2, theta2=1.0 (n=2000, M=50, B=100)\n",
            "Composite (Higher) 95% CI:\n",
            "  Avg LOGLIKE: (-0.9920327913942906, -0.9789177799795598)\n",
            "  Tail KS   : (0.03322857499999998, 0.034048774999999996)\n",
            "  Bias      : (0.3321206410907942, 0.34007717435211704)\n",
            "  MSE       : (0.38592304312215137, 0.3968345518797836)\n",
            "Finished Higher in 0.2s\n",
            "\n",
            "Running threshold 'Extreme': theta1=-2.0, theta2=2.0 (n=2000, M=50, B=100)\n",
            "Composite (Extreme) 95% CI:\n",
            "  Avg LOGLIKE: (-1.4132804325626607, -1.3886500068266248)\n",
            "  Tail KS   : (0.047681375, 0.04781945)\n",
            "  Bias      : (-0.006697986477049416, 0.01124715661616394)\n",
            "  MSE       : (1.2729165512768479, 1.2896101623546443)\n",
            "Finished Extreme in 0.3s\n",
            "\n",
            "Saved CSV to threshold_composite_results_composite_thresholds_summary.csv and LaTeX to threshold_composite_results_composite_thresholds_summary.tex (if no error).\n",
            "\n",
            "Threshold sensitivity summary (Composite only):\n",
            "threshold_label    theta1   theta2  avglog_mean  avglog_lo  avglog_hi  tailks_mean  tailks_lo  tailks_hi  bias_mean   bias_lo   bias_hi  mse_mean   mse_lo   mse_hi\n",
            "       Baseline -0.300000 0.300000    -1.034765  -1.039810  -1.029300     0.014202   0.013628   0.014708   0.002396 -0.000843  0.005625  0.184341 0.180816 0.188450\n",
            "          Lower -1.000000 0.200000    -1.201720  -1.208266  -1.192860     0.034136   0.033754   0.034639  -0.335970 -0.338941 -0.332274  0.395042 0.390258 0.399032\n",
            "         Higher -0.200000 1.000000    -0.986159  -0.992033  -0.978918     0.033635   0.033229   0.034049   0.336247  0.332121  0.340077  0.391145 0.385923 0.396835\n",
            "        Extreme -2.000000 2.000000    -1.400803  -1.413280  -1.388650     0.047753   0.047681   0.047819   0.002913 -0.006698  0.011247  1.279544 1.272917 1.289610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CMUlfNEsQ-Ky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}